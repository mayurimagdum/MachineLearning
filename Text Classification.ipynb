{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('course description', ['In this practical, hands-on course, learn how to do data preparation, data munging, data visualization, and predictive analytics. ', 'PHP is the most popular server-side language used to build dynamic websites, and though it is not especially difficult to use, nonprogrammers often find it intimidating. '])\n"
     ]
    }
   ],
   "source": [
    "with open('Course-Descriptions.txt','r') as fh:\n",
    "    desc = fh.read().splitlines()\n",
    "    print('course description',desc[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('features identified', [u\"'ll\", u\"'re\", u\"'s\", u'(', u')', u',', u'.', u'?', u'actively', u'adopting', u'amazon', u'analysis', u'analytics', u'application', u'applied', u'architect', u'architecture', u'around', u'aspect', u'associate', u'aws', u'basic', u'become', u'begin', u'big', u'bolster', u'build', u'built', u'business', u'career', u'certification', u'certified', u'choice', u'chrome', u'clean', u'cleaner', u'cloud', u'code', u'coding', u'collecting', u'compare', u'computing', u'consider', u'cost', u'course', u'cover', u'create', u'creating', u'data', u'data\\u2014from', u'decision', u'definitely', u'design', u'designed', u'developer', u'development', u'difficult', u'dominates', u'due', u'dynamic', u'effective', u'efficiency', u'efficient\\u2014helping', u'employer', u'encourage', u'enough', u'ensuring', u'especially', u'essential', u'every', u'everything', u'examines', u'exciting', u'explore', u'extracting', u'familiarizing', u'fast', u'faster', u'feature', u'field', u'filtering', u'find', u'focusing', u'foundational', u'framework', u'front-end', u'full-stack', u'gain', u'go', u'go-to', u'going', u'good', u'google', u'graphical', u'gui', u'hand', u'hands-on', u'help', u'ibm', u'ideal', u'important', u'including', u'industry-leading', u'infrastructure', u'ingest', u'integral', u'interested', u'interface', u'intimidating', u'javascript', u'job', u'jump', u'keep', u'kind', u'know', u'language', u'large', u'leading', u'learn', u'learning', u'look', u'looking', u'machine', u'make', u'manager', u'many', u'mapping', u'market', u'matter', u'minimal', u'mining', u'modern', u'munging', u\"n't\", u'nearly', u'network', u'new', u'node.js', u'nonprogrammers', u'nowadays', u'numpy', u'object-oriented', u'offered', u'often', u'one', u'option', u'organization', u'package', u'panda', u'path', u'pattern', u'people', u'php', u'pivot', u'platform', u'play', u'popular', u'potential', u'power', u'powerful', u'practical', u'predictive', u'preparation', u'private', u'probably', u'productive', u'professional', u'programming', u'project', u'provide', u'providing', u'python', u'python\\u2014the', u'querying', u'r', u'range', u'raw', u'real', u'reduce', u'refresh', u'requires', u'reuse', u'right', u'role', u'runtime', u'scalable', u'science', u'scientist', u'scripting', u'searching', u'select', u'series', u'server-side', u'service', u'sharp', u'similar', u'simplicity', u'skill', u'skilled', u'skillset', u'solution', u'specialist', u'specifically', u'start', u'strategy', u'strengthen', u'systematic', u'tackling', u'team', u'tech-related', u'technology', u'third-party', u'though', u'tool', u'toward', u'traditional', u'trained', u'transitioning', u'tree', u'understanding', u'use', u'used', u'user', u'using', u'value', u'versed', u'visualization', u'visualizing', u'want', u'web', u'website', u'whether', u'widely', u'wo', u'work', u'workflow', u'working', u'yahoo'])\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmetizer = WordNetLemmatizer()\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "def customtokenize(str):\n",
    "    tokens=nltk.word_tokenize(str)\n",
    "    nostop = list(filter(lambda token: token not in stopwords.words('english'), tokens))\n",
    "    lemmatized=[lemmetizer.lemmatize(word) for word in nostop ]\n",
    "    return lemmatized\n",
    "\n",
    "# Generation TF IDF \n",
    "Vectorizer = TfidfVectorizer(tokenizer = customtokenize)\n",
    "tfidf_matrix = Vectorizer.fit_transform(desc)\n",
    "print(\"features identified\" ,Vectorizer.get_feature_names())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('sample', ['Data-Science', 'Programming', 'Programming'])\n"
     ]
    }
   ],
   "source": [
    "# loading classification data \n",
    "with open('Course-Classification.txt','r') as fh:\n",
    "    classification = fh.read().splitlines()\n",
    "    print(\"sample\",classification[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "int_classes = le.fit_transform(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "X_train,X_test,y_train,y_test = train_test_split(tfidf_matrix,int_classes,random_state =0)\n",
    "classifier = MultinomialNB().fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('confusion Matrix:', array([[1, 0, 0],\n",
      "       [0, 0, 1],\n",
      "       [1, 0, 2]]))\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print('confusion Matrix:', metrics.confusion_matrix(y_test,pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
